{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Time series forecasting\n",
    "\n",
    "This notebook demonstrates the usage of different `ramsey` models on time series data from the [M4 Competition](https://www.sciencedirect.com/science/article/pii/S0169207019301128). First, we import the necessary libraries and enable 64-bit support for `JAX`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO(simon): add AR models and ConvCNP models, remove experimental RANP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import palettes\n",
    "from jax import numpy as jnp\n",
    "from jax import random as jr\n",
    "from jax.config import config\n",
    "\n",
    "from ramsey.data import m4_data\n",
    "\n",
    "config.update(\"jax_enable_x64\", True)\n",
    "palettes.set_theme()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We first load the hourly M4 competition time series data. After removing all time series that contain NaNs, we get 245 time series with 1008 observations (time points) each."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "data = m4_data()\n",
    "y = data.y\n",
    "\n",
    "y.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Of these time series we select four (that have sufficient variety) and to make training times shorter we only select 200 observations of each time series which we (arbitrarily) split into 180 training samples and 20 test samples. We also standardize them, because as of now, our GP models don't support mean functions."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_series = 4\n",
    "idxs_series = jnp.array([28, 32, 242, 12])\n",
    "\n",
    "n = 200\n",
    "n_train = 180\n",
    "\n",
    "x = jnp.arange(n) / n_train\n",
    "x = jnp.tile(x, [n_series, 1]).reshape((n_series, n, 1))\n",
    "y = y[idxs_series, :n, :]\n",
    "y = (y - y.mean(axis=1, keepdims=True)) / y.std(axis=1, keepdims=True)\n",
    "\n",
    "x_train, x_test = x[:, :n_train, :], x[:, n_train:, :]\n",
    "y_train, y_test = y[:, :n_train, :], y[:, n_train:, :]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's have a look at the time series:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cols = palettes.discrete_sequential_colors(1)\n",
    "_, axes = plt.subplots(figsize=(10, 4), nrows=2, ncols=2)\n",
    "\n",
    "for _, (idx, ax) in enumerate(zip([0, 1, 2, 3], axes.flatten())):\n",
    "    xs = np.squeeze(x[idx, :, :])\n",
    "    ys = np.squeeze(y[idx, :, :])\n",
    "    idxs = np.argsort(xs)\n",
    "    ax.plot(xs[idxs], ys[idxs], color=\"black\", alpha=0.5)\n",
    "    ax.scatter(xs[idxs], ys[idxs], color=\"#204a87\", marker=\"+\", alpha=0.75)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gaussian Process (GP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "To fit a Gaussian process, we import the GP class, some covariance functions, and a function for training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from ramsey.experimental import (\n",
    "    GP,\n",
    "    ExponentiatedQuadratic,\n",
    "    Periodic,\n",
    "    train_gaussian_process,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we define the kernel. As shown below a combination of different basic kernel functions is used."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_gaussian_process():\n",
    "    kernel = ExponentiatedQuadratic() + Periodic(x[0, 1, 0] * 24)\n",
    "    gp = GP(kernel)\n",
    "    return gp"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we define functions for training the GP and plotting the results."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train(rng_key, y, x):\n",
    "    gaussian_process = get_gaussian_process()\n",
    "    params, _ = train_gaussian_process(rng_key, gaussian_process, x=x, y=y)\n",
    "\n",
    "    return gaussian_process, params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot(ax, seed, gaussian_process, params, y_train, x_train, y_test, x_test):\n",
    "    x_star = jnp.concatenate((x_train, x_test))\n",
    "    apply_key, seed = jr.split(seed)\n",
    "    posterior_dist = gaussian_process.apply(\n",
    "        variables=params,\n",
    "        rngs={\"sample\": apply_key},\n",
    "        x=x_train,\n",
    "        y=y_train,\n",
    "        x_star=x_star,\n",
    "    )\n",
    "\n",
    "    sample_key, seed = jr.split(seed)\n",
    "    y_star = posterior_dist.sample(sample_key, (100,))\n",
    "    y_star_mean = jnp.mean(y_star, axis=0)\n",
    "    y_star_cis = jnp.quantile(y_star, q=jnp.array([0.05, 0.95]), axis=0)\n",
    "\n",
    "    ax.plot(\n",
    "        jnp.squeeze(x_test),\n",
    "        jnp.squeeze(y_test),\n",
    "        color=\"black\",\n",
    "        alpha=1,\n",
    "        linestyle=\"dashed\",\n",
    "        label=\"Test data\",\n",
    "    )\n",
    "    ax.axvline(x_test[0], color=\"red\")\n",
    "    ax.scatter(\n",
    "        jnp.squeeze(x_train),\n",
    "        jnp.squeeze(y_train),\n",
    "        color=\"black\",\n",
    "        marker=\"+\",\n",
    "        label=\"Train data\",\n",
    "    )\n",
    "    ax.plot(\n",
    "        jnp.squeeze(x_star),\n",
    "        jnp.squeeze(y_star_mean),\n",
    "        color=\"#204a87\",\n",
    "        alpha=0.9,\n",
    "        label=\"Posterior mean\",\n",
    "    )\n",
    "    ax.fill_between(\n",
    "        jnp.squeeze(x_star),\n",
    "        y_star_cis[0],\n",
    "        y_star_cis[1],\n",
    "        color=\"#204a87\",\n",
    "        alpha=0.2,\n",
    "        label=\"90% Posterior interval\",\n",
    "    )\n",
    "    ax.grid()\n",
    "    ax.set_frame_on(False)\n",
    "    return ax"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We finally train one GP per time series and visualize forecasts on the test data."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rng_keys = [\n",
    "    jr.PRNGKey(0),\n",
    "    jr.PRNGKey(2),\n",
    "    jr.PRNGKey(0),\n",
    "    jr.PRNGKey(0),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
    "for _, (idx, ax) in enumerate(zip(range(n_series), axes.flatten())):\n",
    "    x_train_single = x_train[idx]\n",
    "    y_train_single = y_train[idx]\n",
    "    x_test_single = x_test[idx]\n",
    "    y_test_single = y_test[idx]\n",
    "    gaussian_process, params = train(\n",
    "        rng_keys[idx], y_train_single, x_train_single\n",
    "    )\n",
    "    ax = plot(\n",
    "        ax,\n",
    "        rng_keys[idx],\n",
    "        gaussian_process,\n",
    "        params,\n",
    "        y_train_single,\n",
    "        x_train_single,\n",
    "        y_test_single,\n",
    "        x_test_single,\n",
    "    )\n",
    "    if idx == 3:\n",
    "        ax.legend(bbox_to_anchor=(1.55, 1.15), frameon=False)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Neural Process (NP)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For time series forecasting with NPs we'll make use of a recurrent attentive neural process. We can again use a pre-defined function for training."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import jax\n",
    "from flax import linen as nn\n",
    "\n",
    "from ramsey import MLP, MultiHeadAttention, train_neural_process\n",
    "from ramsey.experimental import RANP"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we define a conventional neural process."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_neural_process():\n",
    "    dim = 128\n",
    "    np = RANP(\n",
    "        decoder=nn.Sequential(\n",
    "            [\n",
    "                nn.RNN(\n",
    "                    nn.LSTMCell(\n",
    "                        features=20, dtype=jnp.float64, param_dtype=jnp.float64\n",
    "                    )\n",
    "                ),\n",
    "                jax.nn.relu,\n",
    "                nn.Dense(2),\n",
    "            ]\n",
    "        ),\n",
    "        latent_encoder=(MLP([dim] * 3), MLP([dim, dim * 2])),\n",
    "        deterministic_encoder=(\n",
    "            MLP([dim] * 3),\n",
    "            MultiHeadAttention(\n",
    "                num_heads=8, head_size=16, embedding=MLP([dim] * 2)\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    return np"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Next we define a function for training the NP."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def train_np(key, x, y, n_context, n_target):\n",
    "    neural_process = get_neural_process()\n",
    "    params, _ = train_neural_process(\n",
    "        key,\n",
    "        neural_process,\n",
    "        x=x,\n",
    "        y=y,\n",
    "        n_context=n_context,\n",
    "        n_target=n_target,\n",
    "        n_iter=20000,\n",
    "    )\n",
    "\n",
    "    return neural_process, params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We split the training data into two sets: a set of context points and a set of target points to train on. Then we train the model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n_context = 50\n",
    "n_target = 100\n",
    "\n",
    "neural_process, params = train_np(\n",
    "    jr.PRNGKey(12), x_train, y_train, n_context, n_target\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's visualize the results we got:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def plot(\n",
    "    seed,\n",
    "    neural_process,\n",
    "    params,\n",
    "    y_train,\n",
    "    x_train,\n",
    "    y_test,\n",
    "    x_test,\n",
    "    n_context,\n",
    "    n_target,\n",
    "):\n",
    "    sample_key, seed = jr.split(seed)\n",
    "    sample_idxs = jr.choice(\n",
    "        sample_key,\n",
    "        x_train.shape[1],\n",
    "        shape=(n_context + n_target,),\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    fig, axes = plt.subplots(figsize=(15, 10), nrows=2, ncols=2)\n",
    "    for _, (idx, ax) in enumerate(zip(range(n_series), axes.flatten())):\n",
    "        x_train_single = x_train[[idx], ...]\n",
    "        y_train_single = y_train[[idx], ...]\n",
    "        x_test_single = x_test[[idx], ...]\n",
    "        y_test_single = y_test[[idx], ...]\n",
    "\n",
    "        x_star = jnp.concatenate((x_train_single, x_test_single), axis=1)\n",
    "        x_context = x_train_single[:, sample_idxs[:n_context], :]\n",
    "        y_context = y_train_single[:, sample_idxs[:n_context], :]\n",
    "\n",
    "        apply_key, seed = jr.split(seed)\n",
    "        y_star = neural_process.apply(\n",
    "            variables=params,\n",
    "            rngs={\"sample\": apply_key},\n",
    "            x_context=x_context,\n",
    "            y_context=y_context,\n",
    "            x_target=x_star,\n",
    "        ).mean\n",
    "\n",
    "        ax.plot(\n",
    "            jnp.squeeze(x_train_single),\n",
    "            jnp.squeeze(y_train_single),\n",
    "            color=\"black\",\n",
    "            alpha=1,\n",
    "            label=\"past data\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            jnp.squeeze(x_test_single),\n",
    "            jnp.squeeze(y_test_single),\n",
    "            color=\"black\",\n",
    "            alpha=1,\n",
    "            linestyle=\"dashed\",\n",
    "            label=\"test data\",\n",
    "        )\n",
    "        ax.axvline(jnp.squeeze(x_test_single[0, 0]), color=\"red\")\n",
    "        ax.scatter(\n",
    "            jnp.squeeze(x_train_single),\n",
    "            jnp.squeeze(y_train_single),\n",
    "            color=\"red\",\n",
    "            marker=\"+\",\n",
    "            alpha=0.45,\n",
    "            label=\"training data\",\n",
    "        )\n",
    "        ax.plot(\n",
    "            jnp.squeeze(x_star),\n",
    "            jnp.squeeze(y_star),\n",
    "            color=\"blue\",\n",
    "            alpha=0.45,\n",
    "            label=\"posterior mean\",\n",
    "        )\n",
    "        ax.grid()\n",
    "        ax.set_frame_on(False)\n",
    "        if idx == 3:\n",
    "            ax.legend(bbox_to_anchor=(1.55, 1.15), frameon=False)\n",
    "\n",
    "\n",
    "plot(\n",
    "    jr.PRNGKey(1),\n",
    "    neural_process,\n",
    "    params,\n",
    "    y_train,\n",
    "    x_train,\n",
    "    y_test,\n",
    "    x_test,\n",
    "    n_context,\n",
    "    n_target,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ramsey-dev",
   "language": "python",
   "name": "ramsey-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "67d7f2a30cbedbe3d121d11a8f3ae0772195d8b49a947a02bd948bd49bce386d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
